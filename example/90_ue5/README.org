- tutorial c++ unreal engine 5: https://youtu.be/nvruYLgjKkk
- apparently better video: https://www.youtube.com/watch?v=g9dU0eCy8RI&t=0s
  - starting C++ tutorial from blank project
- corresponding github: https://github.com/Ohjurot/UE5-Cpp-Tutorial

* How to install VS Code

  - https://docs.unrealengine.com/5.0/en-US/setting-up-visual-studio-code-for-unreal-engine/
  - Download VS Code
  - C/C++ extension
  - Compiler toolset LLVM/Clang
  - LLDB extension
    
  - Set up intellisense


* Build UE5 from source
  - download release from github (currently 5.1)
  - run some scripts
    - first one downloads 20GB
    - second generates build scripts (or something), takes 1min30sec
    - run make (needs 1.5GB ram per core, i can only use 8 cores)
      build time was ca 90min


 * ChatGPT Experiments

   ** C++ UE5

 #+begin_example

Write a simple C++ example for Unreal Engine 5.

#include "Engine.h"

int main()
{
	// Create a new instance of the engine
	UEngine* Engine = NewObject<UEngine>();

	// Set the desired frame rate
	Engine->SetTargetFPS(60);

	// Begin the game loop
	while (Engine->IsRunning())
	{
		// Update the engine
		Engine->Tick();
	}

	// Cleanup
	Engine->Destroy();

	return 0;
}
 #+end_example


 ** UE5 Sphere

 #+begin_example

Write a simple C++ example for Unreal Engine 5. Draw a bouncing red sphere.


#include "Com#include "Components/StaticMeshComponent.h"
#include "Components/SceneComponent.h"
#include "GameFramework/Actor.h"

#include "DrawDebugHelpers.h"

#include "Engine/World.h"

class ABouncingSphere : public AActor
{
	GENERATED_BODY()

public:
	ABouncingSphere()
	{
		PrimaryActorTick.bCanEverTick = true;

		// Create the sphere mesh
		SphereMesh = CreateDefaultSubobject<UStaticMeshComponent>(TEXT("SphereMesh"));
		SphereMesh->SetStaticMesh(ConstructorHelpers::FObjectFinder<UStaticMesh>(TEXT("/Engine/BasicShapes/Sphere")).Object);
		SphereMesh->SetWorldScale3D(FVector(0.2f, 0.2f, 0.2f));
		SphereMesh->SetCollisionEnabled(ECollisionEnabled::QueryOnly);
		SphereMesh->SetCollisionObjectType(ECollisionChannel::ECC_WorldDynamic);
		SphereMesh->SetCollisionResponseToAllChannels(ECollisionResponse::ECR_Ignore);
		SphereMesh->SetCollisionResponseToChannel(ECollisionChannel::ECC_WorldDynamic, ECollisionResponse::ECR_Overlap);
		RootComponent = SphereMesh;

		// Create the sphere physics
		SpherePhysics = CreateDefaultSubobject<USceneComponent>(TEXT("SpherePhysics"));
		SpherePhysics->SetMobility(EComponentMobility::Movable);
		SpherePhysics->SetupAttachment(RootComponent);

		// Set the sphere's color
		SphereMesh->SetMaterial(0, ConstructorHelpers::FObjectFinder<UMaterial>(TEXT("/Engine/BasicShapes/BasicShapeMaterial")).Object);
		SphereMesh->SetVectorParameterValue(FName("Color"), FLinearColor(1.0f, 0.0f, 0.0f));
	}

	void BeginPlay()
	{
		Super::BeginPlay();

		// Set the initial velocity
		SpherePhysics->SetPhysicsLinearVelocity(FVector(0.0f, 0.0f, 10.0f));
	}

	void Tick(float DeltaTime)
	{
		Super::Tick(DeltaTime);

		// Calculate the new velocity
		FVector Velocity = SpherePhysics->GetPhysicsLinearVelocity();
		Velocity.Z = Velocity.Z * -0.8f;
		SpherePhysics->SetPhysicsLinearVelocity(Velocity);

		// Draw a debug sphere
		DrawDebugSphere(GetWorld(), GetActorLocation(), 10.0f, 8, FColor(255, 0, 0));
	}

private:
	UStaticMeshComponent* SphereMesh;
	USceneComponent* SpherePhysics;

};


 #+end_example


 ** EMVA


- I want code that allows the calibration of a linear camera according to EMVA 1288.


- EMVA 1288 is a standard for measuring and reporting the performance
  of digital cameras. It is a comprehensive method that requires a
  test chart setup, camera settings, and a set of measurements taken
  with the camera.

- Unfortunately, there is no code that allows a linear camera to be
  calibrated according to EMVA 1288. Instead, you will need to use
  specialized software and/or hardware to complete the calibration
  process. For example, you can use software such as Photonfocus
  Calibration or hardware such as the Photonfocus EMVA 1288
  Calibration Kit to help you calibrate your linear camera.

- load PNG with R

#+begin_example
Write R code to load a sequence of 2D gray PNG image.

library(png)

img_list <- list.files(path = ".", pattern = "*.png", full.names = TRUE)

for (i in seq_along(img_list)){
  img <- readPNG(img_list[i])
  # add code to process the 2D gray PNG image
}

#+end_example


- compute statistics

#+begin_example

Write R code to load a sequence of 2D gray PNG image. Compute the variance and the mean of each pixel over all the images.

# Load packages
library(png)

# Create an empty vector to store the data
data <- vector(mode="numeric", length=1000)

# Loop through images
for (i in 1:1000) {
  # Load image and store into data vector
  img <- readPNG(paste0("image",i,".png"))
  data[i] <- img
}

# Compute the variance and the mean of each pixel over all images
pixel_variance <- apply(data, c(1,2), var)
pixel_mean <- apply(data, c(1,2), mean)
#+end_example

- continue:

#+begin_example

Plot variance against mean. Perform a linear fit. Print slope and intercept with error estimates.

# Plot variance against mean
plot(pixel_mean, pixel_variance, main="Variance vs Mean of Pixels")

# Perform linear fit
fit <- lm(pixel_variance ~ pixel_mean)

# Print slope and intercept with error estimates
summary(fit)
#+end_example


** Lane-Emden (star model, astronomy)
- python
#+begin_example
Implement a solver for the Lane-Emden equation in Python.

The Lane-Emden equation is a second-order nonlinear ordinary differential equation that describes the behavior of certain self-gravitating systems such as stars or gas clouds. It is given by:

d^2ξ/dθ^2 + (2/θ)dξ/dθ + ξ^n = 0

Where ξ(θ) is the unknown function and n is a constant.

The following code provides a solver for the Lane-Emden equation in Python:

import numpy as np

def lane_emden(n, theta):
    # Define the ODE
    def f(x, t):
        ξ, η = x
        return [η, -(2./t)*η - ξ**n]
    
    # Define the initial conditions
    x0 = [1, 0]
    
    # Solve the ODE
    soln = integrate.solve_ivp(f, [1e-6, theta], x0)
    
    # Return the solution
    return soln.y[0][-1]

# Test the solver
n = 3
theta = 10
print(lane_emden(n, theta)) # 0.08799616713117206

#+end_example

- continue
#+begin_example

# Plot results for three different positions in the Hertzsprung–Russell diagram
import matplotlib.pyplot as plt

# Define constants
n_values = [1, 3/2, 5]
theta_values = np.linspace(1e-6, 10, 100)

# Solve for each n value
for n in n_values:
    ξ_values = [lane_emden(n, theta) for theta in theta_values]
    
    # Plot the results
    plt.plot(ξ_values, theta_values, label=f'n = {n}')
    
# Label the plot
plt.xlabel('ξ')
plt.ylabel('θ')
plt.title('Lane-Emden Equation')
plt.legend()
plt.show()
#+end_example


- in go
  - does that make sense? i'm not sure
#+begin_example

Implement a solver for the Lane-Emden equation in Go.

//Function to solve Lane-Emden equation
func SolveLaneEmden(x float64, n float64) float64 {

	//Initialize variables
	var y float64 = 1
	var dy float64 = 0
	var h float64 = 1e-4

	//Iterate until x reaches 0
	for x >= 0 {
		//Calculate derivatives
		dy = y + (x*x*y)/(n-1)
		d2y := -2*x*dy/n - (x*x*dy)/(n-1)

		//Calculate new y value
		y += (h/2)*(dy + (h/2)*d2y)

		//Decrement x
		x -= h
	}

	//Return y
	return y
}
#+end_example

** Optical Fiber


- Derive the characteristic equation for a rotationally symmetric optical fiber with a core and infinite cladding.
 - That is not quite correct.
#+begin_example


The characteristic equation for a rotationally symmetric optical fiber with a core and infinite cladding is given by:

n_1^2 - n_2^2 = (2π/λ)^2n_1n_2(n_1^2 - n_2^2)r^2,

where n_1 is the refractive index of the core, n_2 is the refractive index of the cladding, λ is the wavelength of light, and r is the core radius.

#+end_example

- continue

#+begin_example


The solution for the scalar approximation is given by:

n_1 = n_2 + (2π/λ)^2n_1n_2r^2.
#+end_example


** Common Lisp socket

- Write Common Lisp code that listens on a socket. When it reads the
  string "Hello" the programm must return "World".

#+begin_example


(defun start-server ()
  (let ((s (socket:socket-server 8888 :element-type 'character :external-format '(:utf-8 :eol-style :crlf))))
    (loop (multiple-value-bind (str conn)
                        (socket:socket-accept s)
                      (if (string= "Hello" str)
                          (socket:socket-send conn "World")
                        (socket:socket-send conn "Error")))
           (sleep 5))))

(start-server)


#+end_example

** Android socket

#+begin_example

Write Kotlin code for an Android App that opens a socket and that listens on a socket. When it reads the string "Hello" the programm must return "World".

import java.net.ServerSocket
import java.io.BufferedReader
import java.io.InputStreamReader

fun main() {
    val serverSocket = ServerSocket(8080)
    println("Listening on port 8080")
    while (true) {
        val clientSocket = serverSocket.accept()
        val inFromClient = BufferedReader(InputStreamReader(clientSocket.getInputStream()))
        val inputLine = inFromClient.readLine()
        if (inputLine == "Hello") {
            println("Received: $inputLine")
            clientSocket.getOutputStream().write(("World\n").toByteArray())
        }
    }
}
#+end_example


** Common Lisp C++ generator

#+begin_example

Write Common Lisp code that reads s-expressions and generates C++ code.

(defun s-expr-to-cpp (expr)
  (cond
    ((atom expr) (format nil "~a" expr))
    ((eq (car expr) 'quote) (format nil "~a" (cadr expr)))
    ((or (eq (car expr) '+) (eq (car expr) '-))
     (format nil "(~a ~a ~a)"
             (s-expr-to-cpp (second expr)) (car expr) (s-expr-to-cpp (third expr))))
    ((or (eq (car expr) '*) (eq (car expr) '/))
     (format nil "(~a ~a ~a)"
             (s-expr-to-cpp (second expr)) (car expr) (s-expr-to-cpp (third expr))))
    (t (error "Unrecognized expression ~a" expr))))
#+end_example

- that is not what i want, i also don't see how i could fix that

** C++ popl

#+begin_example
Write C++ code that parses command line arguments with popl. It should support the verbose switch with the flag -v. If -h is given as an argument print the usage documentation and exit the program.

#include <iostream>
#include <string>
#include <popl.hpp>

int main(int argc, char* argv[]) {
    // Create a parser.
    popl::OptionParser parser;
    // Define the options.
    popl::Flag v{ parser, "v", "verbose", "enable verbose mode" };
    popl::Flag h{ parser, "h", "help", "print usage" };
    // Parse the command line arguments.
    try {
        parser.parse(argc, argv);
    }
    catch (const std::exception& e) {
        std::cerr << e.what() << "\n";
        return 1;
    }
    // Check if the -h flag was given.
    if (h.is_set()) {
        std::cout << parser << "\n";
        return 0;
    }
    // Check if the -v flag was given.
    if (v.is_set()) {
        std::cout << "Verbose mode enabled.\n";
    }
    // Do something with the command line arguments.
    // ...
    return 0;
}

#+end_example


- i want positional file arguments
#+begin_example

Write C++ code that parses command line arguments with popl. It should support the verbose switch with the flag -v. If -h is given as an argument print the usage documentation and exit the program. After the optional flags a sequence of one or more file arguments can follow.


#include <iostream>
#include <popl.hpp>

using namespace popl;

// Function to print usage documentation
void printUsageDoc() {
	std::cout << "Usage: myprogram [-v] file1 [file2 ...]" << std::endl;
	std::cout << "Flags:" << std::endl;
	std::cout << "-v   Enable verbose mode" << std::endl;
	std::cout << "-h   Print usage documentation and exit" << std::endl;
}

int main(int argc, char ** argv) {
	// Create option parser
	OptionParser op("myprogram");

	// Add verbose switch
	Switch verbose_switch(op, "v", "verbose", "Enable verbose mode");

	// Add help switch
	Switch help_switch(op, "h", "help", "Print usage documentation and exit");

	// Parse command line arguments
	try {
		op.parse(argc, argv);
	}
	catch (const std::exception& e) {
		std::cerr << e.what() << std::endl;
		op.printHelp(std::cerr);
		return EXIT_FAILURE;
	}

	// Print usage documentation if help switch is given
	if (help_switch.is_set()) {
		printUsageDoc();
		return EXIT_SUCCESS;
	}

	// Print verbose message if verbose switch is given
	if (verbose_switch.is_set())
		std::cout << "Verbose mode is enabled" << std::endl;

	// Handle file arguments
	std::vector<std::string> files = op.free_args();
	for (const std::string& file : files)
		std::cout << "Processing file: " << file << std::endl;

	return EXIT_SUCCESS;
}
#+end_example


** C++ libtorch

- pose estimation on image
#+begin_example
Write C++ code with libtorch that opens an image and performs pose estimation.

#include <torch/torch.h>
#include <opencv2/opencv.hpp>
#include <iostream>

// Read the image
cv::Mat image = cv::imread("image.jpg");

// Convert to tensor
at::Tensor tensor_image = torch::from_blob(image.data, {1, image.rows, image.cols, 3}, at::kByte);

// Normalize the image
tensor_image = tensor_image.toType(at::kFloat) / 255.0;

// Create the network
auto network = torch::nn::Sequential(torch::nn::Conv2d(3, 32, 3),
                                    torch::nn::ReLU(),
                                    torch::nn::MaxPool2d(2),
                                    torch::nn::Conv2d(32, 64, 3),
                                    torch::nn::ReLU(),
                                    torch::nn::MaxPool2d(2),
                                    torch::nn::Conv2d(64, 128, 3),
                                    torch::nn::ReLU(),
                                    torch::nn::MaxPool2d(2));

// Perform pose estimation
torch::Tensor output = network->forward(tensor_image);

std::cout << "Pose estimation output: " << output << std::endl;

#+end_example

- on video

#+begin_example
#include <torch/torch.h>
#include <opencv2/opencv.hpp>

// Load a pretrained model
torch::jit::script::Module model = torch::jit::load("pose_estimation_model.pt");

// Create a cv::VideoCapture object to capture from a camera
cv::VideoCapture cap(0);

while (true) {
    // Capture a frame from the video
    cv::Mat frame;
    cap >> frame;

    // Convert the frame to a tensor
    torch::Tensor tensor_image = torch::from_blob(frame.data, {1, frame.rows, frame.cols, 3}, torch::kByte);
    tensor_image = tensor_image.permute({0, 3, 1, 2});
    tensor_image = tensor_image.to(torch::kF32);

    // Run the model
    std::vector<torch::jit::IValue> inputs;
    inputs.push_back(tensor_image);
    at::Tensor output = model.forward(inputs).toTensor();

    // Extract the pose from the output
    float x_pos = output[0][0].item<float>();
    float y_pos = output[0][1].item<float>();

    // Draw the pose on the frame
    cv::circle(frame, cv::Point(x_pos, y_pos), 3, cv::Scalar(0,255,0), -1);

    // Display the frame
    cv::imshow("Pose Estimation", frame);

    // Check for user input
    int key = cv::waitKey(1);
    if (key == 27) {
        break;
    }
}

#+end_example


** C++ CGAL

#+begin_example

Write C++ code using CGAL.  Open a point cloud from a file. Fit a plane to the points with a z height lower than 10.


#include <CGAL/Simple_cartesian.h>
#include <CGAL/Plane_3.h>
#include <CGAL/IO/read_xyz_points.h>
#include <CGAL/Point_3.h>
#include <CGAL/Random.h>
#include <CGAL/linear_least_squares_fitting_3.h>

#include <fstream>
#include <iostream>
#include <vector>

typedef CGAL::Simple_cartesian<double> K;
typedef K::FT FT;
typedef K::Point_3 Point;
typedef K::Plane_3 Plane;
typedef std::vector<Point> Points;

int main()
{
  Points points;
  std::ifstream stream("data/points.xyz");
  if (!stream ||
      !CGAL::read_xyz_points(stream, std::back_inserter(points)))
  {
    std::cerr << "Error: cannot read file data/points.xyz" << std::endl;
    return EXIT_FAILURE;
  }

  Plane plane;

  Points filtered_points;
  for (auto p : points) {
    if (p.z() < 10) {
      filtered_points.push_back(p);
    }
  }

  CGAL::linear_least_squares_fitting_3(filtered_points.begin(), filtered_points.end(), plane, CGAL::Dimension_tag<0>());

  std::cout << "Fitting plane : " << plane << std::endl;

  return EXIT_SUCCESS;
}
#+end_example
 
** C++ Ceres

#+begin_example

Write C++ read images from two cameras and perform stereo calibration with the ceres-solver.

// Include the necessary libraries
#include<opencv2/opencv.hpp>
#include<ceres/ceres.h>
#include <ceres/rotation.h>

int main()
{
    // Read in the images from the two cameras
    cv::Mat left_image;
    cv::Mat right_image;
    left_image = cv::imread("left.jpg");
    right_image = cv::imread("right.jpg");
    
    // Create the vector of image point correspondences
    std::vector<cv::Point2f> left_points;
    std::vector<cv::Point2f> right_points;
    cv::findChessboardCorners(left_image, cv::Size(7,7), left_points);
    cv::findChessboardCorners(right_image, cv::Size(7,7), right_points);
    
    // Create the vector of 3D point correspondences
    std::vector<cv::Point3f> object_points;
    for (int i = 0; i < 7; i++) {
        for (int j = 0; j < 7; j++) {
            object_points.push_back(cv::Point3f(i, j, 0));
        }
    }
    
    // Create the camera intrinsic parameters
    cv::Matx33d camera_matrix = cv::Matx33d::eye();
    camera_matrix(0,0) = 1.0; //fx
    camera_matrix(1,1) = 1.0; //fy
    camera_matrix(0,2) = 0.5*left_image.cols; //cx
    camera_matrix(1,2) = 0.5*left_image.rows; //cy
    
    // Define the ceres problem
    ceres::Problem problem;
    for (int i = 0; i < left_points.size(); i++) {
        // Define the residual block
        ceres::CostFunction* cost_function =
        new ceres::AutoDiffCostFunction<ReprojectionError, 2, 4, 6>(
            new ReprojectionError(left_points[i], right_points[i], object_points[i], camera_matrix));
        
        // Set the parameters for the problem
        double* R = new double[4];
        double* t = new double[3];
        problem.AddResidualBlock(cost_function, NULL, R, t);
        
        // Set the parameter lower and upper bounds
        problem.SetParameterLowerBound(R, 0, -1.0);
        problem.SetParameterUpperBound(R, 0, 1.0);
        problem.SetParameterLowerBound(t, 0, -1000.0);
        problem.SetParameterUpperBound(t, 0, 1000.0);
    }
    
    // Solve the problem with Ceres
    ceres::Solver::Options options;
    options.linear_solver_type = ceres::DENSE_QR;
    options.minimizer_progress_to_stdout = true;
    ceres::Solver::Summary summary;
    ceres::Solve(options, &problem, &summary);
    
    // Print the results
    std::cout << summary.BriefReport() << std::endl;
    
    return 0;
}
#+end_example
