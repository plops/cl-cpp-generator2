Okay, let's design and implement this C++ architecture using modern C++20 features.

We'll use:
*   `std::vector<std::byte>` for images, pre-sized.
*   Simple structs for `Metadata` and `Measurement`.
*   `std::vector` to hold the actual pool data.
*   A thread-safe queue to manage *indices* of free pool slots.
*   Three separate thread-safe queues to pass *indices* of filled slots to consumers.
*   `std::jthread` for managing threads.
*   `std::atomic_bool` for graceful shutdown.
*   `std::span` could be used by consumers for safe access, but passing the index and letting the consumer access `pool[index]` is also clear. We'll stick to passing indices.

**1. Common Definitions (`common.h`)**

```cpp
#ifndef COMMON_H
#define COMMON_H

#include <vector>
#include <cstddef> // For std::byte
#include <cstdint> // For uintX_t types

// --- Constants ---
constexpr std::size_t IMAGE_WIDTH = 128;
constexpr std::size_t IMAGE_HEIGHT = 128;
constexpr std::size_t IMAGE_SIZE_BYTES = IMAGE_WIDTH * IMAGE_HEIGHT; // Assuming 1 byte per pixel

constexpr std::size_t IMAGE_POOL_SIZE = 10;
constexpr std::size_t METADATA_POOL_SIZE = 12;
constexpr std::size_t MEASUREMENT_POOL_SIZE = 20;

// --- Data Types ---
// Using a type alias for clarity, actual storage managed by the pool
using Image = std::vector<std::byte>;

struct Metadata {
    int i;
    float f; // Renamed 'a' to 'f' for potential clarity, change back if needed
    // Add potential padding if network serialization differs significantly
};

struct Measurement {
    double q;
    double p;
    // Add potential padding if network serialization differs significantly
};

// --- Network Packet IDs ---
enum class PacketType : uint8_t {
    Image = 0,
    Metadata = 1,
    Measurement = 2,
    Unknown = 255 // Or some other indicator
};

// Helper function (simplistic deserialization)
inline PacketType parse_packet_id(const std::vector<std::byte>& packet_data) {
    if (packet_data.empty()) {
        return PacketType::Unknown;
    }
    uint8_t id_val = static_cast<uint8_t>(packet_data[0]);
    switch (id_val) {
        case 0: return PacketType::Image;
        case 1: return PacketType::Metadata;
        case 2: return PacketType::Measurement;
        default: return PacketType::Unknown;
    }
}


#endif // COMMON_H
```

**2. Thread-Safe Queue (`thread_safe_queue.h`)**

This queue will be used for both the free lists and the data queues. It includes a shutdown mechanism.

```cpp
#ifndef THREAD_SAFE_QUEUE_H
#define THREAD_SAFE_QUEUE_H

#include <queue>
#include <mutex>
#include <condition_variable>
#include <optional>
#include <atomic>

template <typename T>
class ThreadSafeQueue {
public:
    ThreadSafeQueue() = default;
    ~ThreadSafeQueue() = default;

    // Non-copyable and non-movable for simplicity
    ThreadSafeQueue(const ThreadSafeQueue&) = delete;
    ThreadSafeQueue& operator=(const ThreadSafeQueue&) = delete;
    ThreadSafeQueue(ThreadSafeQueue&&) = delete;
    ThreadSafeQueue& operator=(ThreadSafeQueue&&) = delete;

    void push(T value) {
        {
            std::lock_guard lock(mtx_);
            // Optional: Add check here if implementing a bounded queue
            queue_.push(std::move(value));
        } // Lock released before notification
        cv_.notify_one();
    }

    // Blocking pop
    std::optional<T> pop() {
        std::unique_lock lock(mtx_);
        cv_.wait(lock, [this] { return !queue_.empty() || stopped_; });

        if (stopped_ && queue_.empty()) {
            return std::nullopt; // Signal shutdown
        }

        if (queue_.empty()) {
             // This case should ideally not happen often with the wait condition,
             // but can occur due to spurious wakeups or race if stop is called
             // after wait but before checking queue_.empty() again inside the lock.
            return std::nullopt;
        }


        T value = std::move(queue_.front());
        queue_.pop();
        return value;
    }

     // Non-blocking pop
    std::optional<T> try_pop() {
        std::lock_guard lock(mtx_);
        if (queue_.empty() || stopped_) { // Don't allow pops after stop signal if empty
            return std::nullopt;
        }
        T value = std::move(queue_.front());
        queue_.pop();
        return value;
    }

    bool empty() const {
        std::lock_guard lock(mtx_);
        return queue_.empty();
    }

    void stop() {
        {
            std::lock_guard lock(mtx_);
            stopped_ = true;
        } // Lock released before notification
        cv_.notify_all(); // Wake up all waiting threads
    }

private:
    mutable std::mutex mtx_; // Mutable to allow locking in const empty()
    std::queue<T> queue_;
    std::condition_variable cv_;
    std::atomic<bool> stopped_{false}; // Use atomic for safe checking without lock in some scenarios, though wait requires lock
};

#endif // THREAD_SAFE_QUEUE_H
```

**3. Data Pool (`data_pool.h`)**

This class template manages the storage, the free list, and the queue for consumers for a specific data type.

```cpp
#ifndef DATA_POOL_H
#define DATA_POOL_H

#include "common.h"
#include "thread_safe_queue.h"
#include <vector>
#include <stdexcept> // For runtime_error
#include <numeric>   // For std::iota
#include <memory>    // For std::addressof

// Forward declaration
template <typename T> class DataPool;

// Non-owning reference to a pool item, ensures item is returned to free list
template <typename T>
class PoolItemReference {
public:
    PoolItemReference(DataPool<T>& pool, std::size_t index)
        : pool_(&pool), index_(index) {}

    // Destructor returns the index to the free list
    ~PoolItemReference() {
        if (pool_) { // Check if moved from
             pool_->return_free_index(index_);
        }
    }

    // Movable
    PoolItemReference(PoolItemReference&& other) noexcept
        : pool_(other.pool_), index_(other.index_) {
        other.pool_ = nullptr; // Prevent double return
    }
    PoolItemReference& operator=(PoolItemReference&& other) noexcept {
        if (this != &other) {
             // Return current index if holding one before overwriting
             if (pool_) {
                pool_->return_free_index(index_);
             }
             pool_ = other.pool_;
             index_ = other.index_;
             other.pool_ = nullptr; // Prevent double return
        }
        return *this;
    }


    // Non-copyable
    PoolItemReference(const PoolItemReference&) = delete;
    PoolItemReference& operator=(const PoolItemReference&) = delete;

    // Access the underlying data (const)
    const T& get() const {
        if (!pool_) throw std::runtime_error("Accessing moved-from PoolItemReference");
        return pool_->get_item(index_);
    }

    // Allow implicit conversion for convenience (use with caution)
    // operator const T&() const { return get(); }

    std::size_t index() const { return index_; }


private:
    DataPool<T>* pool_; // Pointer to the pool to return the index
    std::size_t index_;
};


// --- Data Pool Class ---

template <typename T>
class DataPool {
public:
    DataPool(std::size_t size) : pool_size_(size) {
        // Special handling for Image to pre-allocate vector content
        if constexpr (std::is_same_v<T, Image>) {
            storage_.reserve(size);
            for (std::size_t i = 0; i < size; ++i) {
                // Pre-allocate each vector to the fixed size
                storage_.emplace_back(IMAGE_SIZE_BYTES);
            }
        } else {
            // For structs, just resize the outer vector
            storage_.resize(size);
        }

        // Initialize free list with all indices
        std::vector<std::size_t> initial_indices(size);
        std::iota(initial_indices.begin(), initial_indices.end(), 0);
        for (std::size_t index : initial_indices) {
            free_indices_.push(index);
        }
    }

    // Non-copyable/movable
    DataPool(const DataPool&) = delete;
    DataPool& operator=(const DataPool&) = delete;
    DataPool(DataPool&&) = delete;
    DataPool& operator=(DataPool&&) = delete;

    // Producer: Get a free index (blocks if none available)
    std::optional<std::size_t> acquire_free_index() {
        return free_indices_.pop();
    }

    // Producer: Get mutable access to item data using acquired index
    // Unsafe if index is not valid or not acquired! Use after acquire_free_index.
    T& get_item_for_write(std::size_t index) {
         if (index >= pool_size_) {
            throw std::out_of_range("Pool index out of range");
         }
        // Add runtime check if needed: Ensure index is not currently considered "free"
        return storage_[index];
    }

    // Producer: Place filled index into the consumer queue
    void submit_filled_index(std::size_t index) {
        data_queue_.push(index);
    }

    // Consumer: Get a filled index (blocks if none available)
    // Returns a RAII wrapper that returns the index when it goes out of scope
    std::optional<PoolItemReference<T>> consume_item() {
        std::optional<std::size_t> index_opt = data_queue_.pop();
        if (index_opt) {
            return PoolItemReference<T>(*this, *index_opt);
        } else {
            return std::nullopt; // Shutdown signalled
        }
    }

    // Used by PoolItemReference destructor
    void return_free_index(std::size_t index) {
        // Optional: Add validation that index is valid and was actually in use
        free_indices_.push(index);
    }

    // Used by PoolItemReference::get() - provides const access
    const T& get_item(std::size_t index) const {
         if (index >= pool_size_) {
            throw std::out_of_range("Pool index out of range");
         }
         return storage_[index];
    }


    void stop() {
        free_indices_.stop();
        data_queue_.stop();
    }

private:
    const std::size_t pool_size_;
    std::vector<T> storage_;             // Actual data storage
    ThreadSafeQueue<std::size_t> free_indices_; // Indices of available slots
    ThreadSafeQueue<std::size_t> data_queue_;   // Indices of slots ready for consumers
};


#endif // DATA_POOL_H
```
*Self-correction:* Added `PoolItemReference` RAII wrapper. This simplifies the consumer logic, ensuring indices are automatically returned to the free list when the consumer is done processing the item (i.e., when the `PoolItemReference` goes out of scope). This is safer than relying on the consumer to manually call `return_free_index`.

**4. Producer Logic (`producer.h` / `producer.cpp`)**

We'll keep this simple, likely just a function.

```cpp
#ifndef PRODUCER_H
#define PRODUCER_H

#include "common.h"
#include "data_pool.h"
#include <vector>
#include <chrono>   // For sleep
#include <thread>   // For sleep_for
#include <random>   // For simulation
#include <atomic>
#include <iostream>
#include <cstring>  // For memcpy
#include <arpa/inet.h> // For ntohs (example) - platform specific!

// --- Network Simulation ---
// Simulates receiving a packet over TCP.
// In reality, this would involve socket programming (recv).
inline std::vector<std::byte> receive_simulated_packet(std::mt19937& rng) {
    std::uniform_int_distribution<> type_dist(0, 2);
    PacketType type = static_cast<PacketType>(type_dist(rng));

    std::vector<std::byte> packet;
    packet.push_back(static_cast<std::byte>(type)); // Packet ID

    switch (type) {
        case PacketType::Image: {
            // Network length prefix (example: big-endian uint16_t)
            uint16_t len_net = htons(static_cast<uint16_t>(IMAGE_SIZE_BYTES)); // Host to network short
            packet.resize(1 + sizeof(len_net) + IMAGE_SIZE_BYTES);
            std::memcpy(packet.data() + 1, &len_net, sizeof(len_net));
            // Fill image data with dummy pattern
            for (size_t i = 0; i < IMAGE_SIZE_BYTES; ++i) {
                packet[1 + sizeof(len_net) + i] = static_cast<std::byte>(i % 256);
            }
            break;
        }
        case PacketType::Metadata: {
            Metadata meta = {rng(), static_cast<float>(rng()) / rng.max()};
            packet.resize(1 + sizeof(Metadata));
             // Simplistic: direct memory copy. Assumes sender/receiver compatibility.
             // Real-world: Use proper serialization (protobuf, flatbuffers, manual packing).
            std::memcpy(packet.data() + 1, &meta, sizeof(Metadata));
            break;
        }
        case PacketType::Measurement: {
            Measurement meas = {static_cast<double>(rng()) / rng.max(), static_cast<double>(rng()) / rng.max() * 100.0};
             packet.resize(1 + sizeof(Measurement));
             // Simplistic: direct memory copy.
             std::memcpy(packet.data() + 1, &meas, sizeof(Measurement));
            break;
        }
        default: // Should not happen in this simulation
             packet.clear(); // Indicate error or empty packet
             break;
    }
    return packet;
}


// --- Producer Thread Function ---
inline void producer_task(
    std::stop_token stoken, // std::jthread provides stop_token
    DataPool<Image>& image_pool,
    DataPool<Metadata>& metadata_pool,
    DataPool<Measurement>& measurement_pool)
{
    std::cout << "Producer thread started." << std::endl;
    std::mt19937 rng(std::random_device{}()); // Random number generator for simulation

    while (!stoken.stop_requested()) {
        // 1. Simulate receiving data (replace with actual network receive)
        std::vector<std::byte> packet_data = receive_simulated_packet(rng);
        if (packet_data.empty()) {
            std::cerr << "Producer: Received empty/invalid packet." << std::endl;
            std::this_thread::sleep_for(std::chrono::milliseconds(10)); // Avoid busy-spin on error
            continue;
        }

        // 2. Parse packet type
        PacketType type = parse_packet_id(packet_data);
        const std::byte* data_ptr = packet_data.data() + 1; // Start after ID
        std::size_t data_size = packet_data.size() - 1;


        // 3. Process based on type
        try {
            switch (type) {
                case PacketType::Image: {
                    if (data_size < sizeof(uint16_t)) {
                         std::cerr << "Producer Error: Image packet too small for length prefix.\n";
                         continue;
                    }
                    // Example: Deserialize length prefix (assuming network byte order)
                    uint16_t length_net;
                    std::memcpy(&length_net, data_ptr, sizeof(length_net));
                    uint16_t image_data_len = ntohs(length_net); // Network to host short

                    data_ptr += sizeof(uint16_t);
                    data_size -= sizeof(uint16_t);


                    if (image_data_len != IMAGE_SIZE_BYTES) {
                        std::cerr << "Producer Error: Received image size mismatch. Expected "
                                  << IMAGE_SIZE_BYTES << ", got " << image_data_len << std::endl;
                        continue; // Skip this packet
                    }
                     if (data_size < image_data_len) {
                         std::cerr << "Producer Error: Image packet data size mismatch. Header says " << image_data_len << ", remaining packet is " << data_size << std::endl;
                         continue;
                     }

                    // Acquire free slot (blocks if pool is full)
                    std::optional<std::size_t> index_opt = image_pool.acquire_free_index();
                     if (!index_opt) { // Check if stop was requested during wait
                         std::cout << "Producer: Stop requested while waiting for image slot. Exiting." << std::endl;
                         return; // Exit loop
                     }
                    std::size_t index = *index_opt;

                    // Get reference to the pre-allocated vector in the pool
                    Image& target_image = image_pool.get_item_for_write(index);
                    // Ensure target vector has correct size (should already be set by pool constructor)
                    if(target_image.size() != IMAGE_SIZE_BYTES) {
                         target_image.resize(IMAGE_SIZE_BYTES); // Defensive resize if needed
                    }

                    // Copy data from packet into the pool's vector
                    std::memcpy(target_image.data(), data_ptr, IMAGE_SIZE_BYTES);

                    // Submit the index for consumers
                    image_pool.submit_filled_index(index);
                    // std::cout << "P: Submitted Image " << index << std::endl;
                    break;
                }
                case PacketType::Metadata: {
                     if (data_size < sizeof(Metadata)) {
                         std::cerr << "Producer Error: Metadata packet too small. Expected "
                                   << sizeof(Metadata) << ", got " << data_size << std::endl;
                         continue;
                     }
                    std::optional<std::size_t> index_opt = metadata_pool.acquire_free_index();
                     if (!index_opt) {
                          std::cout << "Producer: Stop requested while waiting for metadata slot. Exiting." << std::endl;
                         return;
                     }
                    std::size_t index = *index_opt;

                    Metadata& target_meta = metadata_pool.get_item_for_write(index);
                    // Simplistic deserialization (direct copy)
                    std::memcpy(&target_meta, data_ptr, sizeof(Metadata));

                    metadata_pool.submit_filled_index(index);
                     // std::cout << "P: Submitted Metadata " << index << std::endl;
                    break;
                }
                case PacketType::Measurement: {
                     if (data_size < sizeof(Measurement)) {
                         std::cerr << "Producer Error: Measurement packet too small. Expected "
                                   << sizeof(Measurement) << ", got " << data_size << std::endl;
                         continue;
                     }
                    std::optional<std::size_t> index_opt = measurement_pool.acquire_free_index();
                     if (!index_opt) {
                          std::cout << "Producer: Stop requested while waiting for measurement slot. Exiting." << std::endl;
                         return;
                     }
                    std::size_t index = *index_opt;

                    Measurement& target_meas = measurement_pool.get_item_for_write(index);
                    // Simplistic deserialization (direct copy)
                    std::memcpy(&target_meas, data_ptr, sizeof(Measurement));

                    measurement_pool.submit_filled_index(index);
                     // std::cout << "P: Submitted Measurement " << index << std::endl;
                    break;
                }
                case PacketType::Unknown:
                     std::cerr << "Producer: Received packet with unknown type." << std::endl;
                    break; // Ignore unknown packets
            }
        } catch (const std::exception& e) {
             // Catch potential errors like out_of_range from get_item_for_write
             // or issues during acquire/submit if queues are stopped unexpectedly.
             std::cerr << "Producer Error: Exception caught: " << e.what() << std::endl;
             // Decide if the producer should continue or stop based on the error.
             // For now, just log and continue. If acquire/submit fails due to stop,
             // the loop condition or the nullopt check should handle exit.
        }


        // Simulate some processing delay or network latency
        // std::this_thread::sleep_for(std::chrono::milliseconds(5));

    } // end while

    std::cout << "Producer thread stopping." << std::endl;
}


#endif // PRODUCER_H
```

**5. Consumer Logic (`consumer.h` / `consumer.cpp`)**

Again, simple functions. We can use a template for the consumer task.

```cpp
#ifndef CONSUMER_H
#define CONSUMER_H

#include "common.h"
#include "data_pool.h"
#include <thread> // For get_id
#include <iostream>
#include <atomic>
#include <string_view>
#include <stop_token> // For std::jthread

// --- Consumer Thread Function Template ---
template <typename T>
inline void consumer_task(
    std::stop_token stoken,
    std::string_view consumer_name,
    DataPool<T>& data_pool)
{
    std::cout << consumer_name << " thread started." << std::endl;

    while (!stoken.stop_requested()) {
        // 1. Consume item (blocks if queue is empty, returns wrapper)
        std::optional<PoolItemReference<T>> item_ref_opt = data_pool.consume_item();

        if (!item_ref_opt) {
            // Queue was stopped and is empty
            if(stoken.stop_requested()) {
                std::cout << consumer_name << ": Stop requested, exiting." << std::endl;
            } else {
                 std::cout << consumer_name << ": Pool queue returned nullopt unexpectedly. Exiting." << std::endl;
            }
            break; // Exit loop
        }

        // RAII object ensures index is returned when item_ref goes out of scope
        PoolItemReference<T>& item_ref = *item_ref_opt;
        const T& data = item_ref.get(); // Get const reference to data
        std::size_t index = item_ref.index(); // Get the index if needed

        // 2. Process the data (read-only)
        // Simulate processing
        if constexpr (std::is_same_v<T, Image>) {
            // Example: Check first byte
            std::byte first_byte = data.empty() ? std::byte{0} : data[0];
            std::cout << consumer_name << ": Processed Image " << index
                      << " (Size: " << data.size() << ", First byte: "
                      << std::to_integer<int>(first_byte) << ")" << std::endl;
        } else if constexpr (std::is_same_v<T, Metadata>) {
            std::cout << consumer_name << ": Processed Metadata " << index
                      << " (i=" << data.i << ", f=" << data.f << ")" << std::endl;
        } else if constexpr (std::is_same_v<T, Measurement>) {
            std::cout << consumer_name << ": Processed Measurement " << index
                      << " (q=" << data.q << ", p=" << data.p << ")" << std::endl;
        }

        // Simulate work
        std::this_thread::sleep_for(std::chrono::milliseconds(10 + (rand() % 20)));

        // 3. Index is automatically returned to the free list when item_ref goes out of scope here.

    } // end while

    std::cout << consumer_name << " thread stopping." << std::endl;
}


#endif // CONSUMER_H
```

**6. Main Application (`main.cpp`)**

```cpp
#include "common.h"
#include "data_pool.h"
#include "producer.h"
#include "consumer.h"

#include <iostream>
#include <thread> // For std::jthread
#include <vector>
#include <chrono>   // For timing/sleep
#include <csignal>  // For signal handling (Ctrl+C)
#include <atomic>

// Global flag for signal handling
std::atomic<bool> shutdown_flag = false;

void signal_handler(int signum) {
    std::cout << "\nInterrupt signal (" << signum << ") received.\n";
    shutdown_flag.store(true);
}


int main() {
    std::cout << "Application starting..." << std::endl;

    // Register signal handler for graceful shutdown on Ctrl+C
    signal(SIGINT, signal_handler);
    signal(SIGTERM, signal_handler);

    // --- Create Pools ---
    // These constructors pre-allocate storage and initialize free lists
    DataPool<Image> image_pool(IMAGE_POOL_SIZE);
    DataPool<Metadata> metadata_pool(METADATA_POOL_SIZE);
    DataPool<Measurement> measurement_pool(MEASUREMENT_POOL_SIZE);

    std::cout << "Pools created." << std::endl;
    std::cout << " - Image Pool Size: " << IMAGE_POOL_SIZE << std::endl;
    std::cout << " - Metadata Pool Size: " << METADATA_POOL_SIZE << std::endl;
    std::cout << " - Measurement Pool Size: " << MEASUREMENT_POOL_SIZE << std::endl;


    // --- Create Threads ---
    std::vector<std::jthread> threads;

    // Producer Thread
    // Use std::ref for pools passed by reference to the thread constructor
    threads.emplace_back(producer_task,
                         std::ref(image_pool),
                         std::ref(metadata_pool),
                         std::ref(measurement_pool));

    // Consumer Threads
    threads.emplace_back(consumer_task<Image>, "Consumer Image", std::ref(image_pool));
    threads.emplace_back(consumer_task<Metadata>, "Consumer Metadata", std::ref(metadata_pool));
    threads.emplace_back(consumer_task<Measurement>, "Consumer Measurement", std::ref(measurement_pool));

    std::cout << "Threads created and started." << std::endl;

    // --- Main Loop / Wait for Shutdown Signal ---
    while (!shutdown_flag.load()) {
        // Keep main thread alive, check flag periodically
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
        // Add other main thread tasks here if any
    }

    // --- Initiate Shutdown ---
    std::cout << "Shutdown signal received. Stopping threads..." << std::endl;

    // 1. Request stop on all jthreads (signals stop_token)
    for (auto& t : threads) {
        t.request_stop();
    }

     // 2. Signal queues to stop (wakes up threads blocked on pop/acquire)
     //    It's important to do this AFTER requesting stop, so threads checking
     //    the stop_token after waking up will see the request.
    image_pool.stop();
    metadata_pool.stop();
    measurement_pool.stop();


    // 3. jthread destructors will automatically join upon leaving scope.
    //    (No explicit join() needed)
    std::cout << "Waiting for threads to finish..." << std::endl;

    // Clear the threads vector, triggering jthread destructors which join.
    threads.clear();


    std::cout << "All threads have finished." << std::endl;
    std::cout << "Application exiting." << std::endl;

    return 0;
}
```

**7. Compilation (Example using g++)**

You'll need a C++20 compliant compiler (like GCC 10+ or Clang 10+).

```bash
g++ -std=c++20 -pthread main.cpp -o pool_app -Wall -Wextra
# Or clang++
# clang++ -std=c++20 -pthread main.cpp -o pool_app -Wall -Wextra
```
*   `-std=c++20`: Enable C++20 standard.
*   `-pthread`: Link the pthreads library (needed for `std::thread`, `std::jthread`, `std::mutex`, etc. on Linux/macOS).
*   `main.cpp`: Assuming all code is included via headers or compiled together. If you split into `.cpp` files, compile them individually and link.
*   `-Wall -Wextra`: Enable helpful warnings.

**Explanation and Design Choices:**

1.  **Pools:** `DataPool<T>` encapsulates the `std::vector<T>` storage, the `ThreadSafeQueue<size_t>` for free indices, and the `ThreadSafeQueue<size_t>` for data ready for consumers.
2.  **Fixed Size Allocation:** The `DataPool` constructor pre-allocates the `std::vector<T>` storage. For `Image`, it specifically iterates and resizes each `std::vector<std::byte>` element to the required `IMAGE_SIZE_BYTES`. This ensures the memory is allocated upfront.
3.  **Index Passing:** Instead of passing pointers or complex objects, simple `size_t` indices are passed through the queues. This is lightweight and safe as long as the pool's lifetime exceeds the threads using it.
4.  **Resource Management (RAII):** The `PoolItemReference<T>` class is key. When a consumer gets an item via `consume_item()`, it receives this wrapper. The wrapper holds a reference to the pool and the item's index. When the wrapper goes out of scope (at the end of the consumer's processing block), its destructor automatically calls `pool.return_free_index(index)`, placing the index back onto the `free_indices_` queue. This prevents index leaks and ensures slots are correctly recycled.
5.  **Thread Safety:** `ThreadSafeQueue` uses `std::mutex` and `std::condition_variable` for safe concurrent access. The `DataPool` itself coordinates access: the producer acquires an index, writes to the *exclusive* slot `storage_[index]`, and then pushes the index. Consumers pop an index, read *only* from `storage_[index]`, and the `PoolItemReference` returns the index. Direct concurrent writes/reads to the *same* index are prevented by this flow.
6.  **`std::jthread`:** Used for automatic joining on destruction and integration with `std::stop_token` for cancellation.
7.  **Graceful Shutdown:** The `std::atomic<bool>` flag, signal handler, `stop_token`, and `ThreadSafeQueue::stop()` method work together:
    *   Ctrl+C sets the atomic flag.
    *   The main thread detects the flag and calls `request_stop()` on all `jthreads`.
    *   It then calls `stop()` on the pools, which wakes up any threads blocked in `pop()` on the internal queues.
    *   Threads check `stoken.stop_requested()` or the `std::nullopt` return from `pop()` and exit their loops.
    *   `jthread` destructors automatically join.
8.  **Network Simulation:** The `receive_simulated_packet` function generates dummy data. Real implementation would involve socket programming (`recv`, potentially Boost.Asio or similar). The example includes basic handling for a length prefix and potential byte order issues (`htons`/`ntohs`), which are critical in real network code.
9.  **Deserialization:** Kept very simple using `memcpy`. **Caution:** This assumes the sender and receiver have identical struct layouts (padding, alignment, endianness). For robust applications, use a proper serialization library (like Protobuf, FlatBuffers, Cap'n Proto, or manual serialization respecting network byte order).
10. **References vs Pointers:** References are used where natural (e.g., `get_item_for_write` returns `T&`). Pointers are used internally in `PoolItemReference` because references cannot be rebound or be null, making a pointer necessary to handle the moved-from state. Indices are used in queues as the primary mechanism.
