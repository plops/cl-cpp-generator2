
- CUDA Support in Visual Studio Code with Julia Reid
  https://www.youtube.com/watch?v=l6PgYhiQr-I


- extensions (bottom icon (4 boxes) in the left icon bar):
  - Remote - SSH
  - C/C++ (contains cuda intelli sense)
  - Nsight Visual Studio Code Edition
  - [ Makefile Tools (probably not required) ]

- start ssh connection (screen with circle in bottom left in icon bar)
  - green rectangle in bottom corner contains remote host name

- click on the extensions tab
  - click on the cloud to install extensions on the remote side
  - C++ and nsight

- open folder (e.g. cuda-samples matrixMul)
  - intellisense works
  - hover on variable
  - right mouse, find all references
  - right mouse, rename symbol (use shift enter for preview)

- .vscode/c_cpp_properties.json
  - /opt/cuda/bin/nvcc
  
- .vscode/tasks.json
  - make dbg=1 SMS=75

- fix CUDA_PATH in Makefile

- terminal-> run build task

- launch.json
  - contains debug settings

- set breakpoints
  - then press f5

- gentoo has cuda_11.5.1_495.29.05_linux.run
  #+begin_example
  sudo mv /usr/bin/python3 /usr/bin/python3_weg
sudo chmod a+x /opt/cuda/nsight-systems-2021.3.3/host-linux-x64/python/bin/python 
sudo ln -s /opt/cuda/nsight-systems-2021.3.3/host-linux-x64/python/bin/python /usr/bin/python3
    #+end_example

- while stopped in cuda click on CUDA: (0,0,0) in bottom right status
  change focus

- add condition expression to break point
#+begin_example
`info cuda kernels
info cuda kernels
  Kernel Parent Dev Grid Status   SMs Mask   GridDim  BlockDim Invocation 
*      0      -   0    1 Active 0xffffffff (20,10,1) (32,32,1) MatrixMulCUDA<32>(,args=[{name="C",value="0x7fffcd92c000"},{name="A",value="0x7fffcd800000"},{name="B",value="0x7fffcd864000"},{name="wA",value="320"},{name="wB",value="640"}]) 
#+end_example


- https://gist.github.com/ax3l/9489132
- https://llvm.org/docs/CompileCudaWithLLVM.html
#+begin_example
clang++ can compile Cuda C++ to ptx
clang++ -x cuda

clang++ -nocudalib -nocudainc -x cuda quadtree.cu
-Lcudapath/lib64
--cuda-path=/opt/cuda
-lcudart_static -ldl -lrt -pthread
--cuda-gpu-arch=sm_35
-ffp-contract=fast
-fcuda-flush-denormals-to-zero=on
-fcuda-approx-transcendentals=on # implied by -ffast-math




#if defined(__clang__) && defined(__CUDA__) && !defined(__CUDA_ARCH__)
// clang compiling CUDA code, host mode.
#endif

#if defined(__clang__) && defined(__CUDA__) && defined(__CUDA_ARCH__)
// clang compiling CUDA code, device mode.
#endif


Programmers can force unrolling and inline using clang’s loop unrolling
pragmas and __attribute__((always_inline)).
#pragma unroll

#pragma unroll 16

#pragma nounroll

#+end_example
- Clang only targets essential CUDA functionality, so for things like
  textures, __managed__, etc. one will need nvcc
- Performance-wise clang is usually on par. Sometimes a bit better (it
  tends to have a bit better optimizer), sometimes a bit worse
  (e.g. NVCC is much more aggressive at unrolling loops). A lot of the
  differences are eliminated due to the fact that both NVCC and clang
  in the end use ptxas which optimizes generated PTX and often
  produces nearly identical SASS for somewhat different PTX from both
  compilers.
- clang supports std::complex
- clang always invokes ptxas to generate sass code
- they have good documents describing the optimizations
- Programmers can force unrolling and inline using clang’s loop
  unrolling pragmas and __attribute__((always_inline)).)
  - https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll

- install sdk on fedora
#+begin_example
wget https://developer.download.nvidia.com/compute/cuda/11.5.1/local_installers/cuda_11.5.1_495.29.05_linux.run
sudo sh cuda_11.5.1_495.29.05_linux.run
#+end_example
